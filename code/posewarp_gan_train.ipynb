{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import data_generation\n",
    "import networks\n",
    "import scipy.io as sio\n",
    "import param\n",
    "import util\n",
    "import truncated_vgg\n",
    "from keras.optimizers import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model_name, gpu_id):\n",
    "    params = param.get_general_params()\n",
    "    network_dir = params['model_save_dir'] + '/' + model_name\n",
    "\n",
    "    if not os.path.isdir(network_dir):\n",
    "        os.mkdir(network_dir)\n",
    "\n",
    "    train_feed = data_generation.create_feed(params, params['data_dir'], 'train')\n",
    "\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.allow_soft_placement = True\n",
    "\n",
    "    gan_lr = 1e-4\n",
    "    disc_lr = 1e-4\n",
    "    disc_loss = 0.1\n",
    "\n",
    "    generator = networks.network_posewarp(params)\n",
    "    generator.load_weights('../models/vgg_100000.h5')\n",
    "\n",
    "    discriminator = networks.discriminator(params)\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=disc_lr))\n",
    "\n",
    "    vgg_model = truncated_vgg.vgg_norm()\n",
    "    networks.make_trainable(vgg_model, False)\n",
    "    response_weights = sio.loadmat('../data/vgg_activation_distribution_train.mat')\n",
    "\n",
    "    gan = networks.gan(generator, discriminator, params)\n",
    "    gan.compile(optimizer=Adam(lr=gan_lr),\n",
    "                loss=[networks.vgg_loss(vgg_model, response_weights, 12), 'binary_crossentropy'],\n",
    "                loss_weights=[1.0, disc_loss])\n",
    "\n",
    "    n_iters = 10000\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    for step in range(n_iters):\n",
    "\n",
    "        x, y = next(train_feed)\n",
    "\n",
    "        gen = generator.predict(x)\n",
    "\n",
    "        # Train discriminator\n",
    "        x_tgt_img_disc = np.concatenate((y, gen))\n",
    "        x_src_pose_disc = np.concatenate((x[1], x[1]))\n",
    "        x_tgt_pose_disc = np.concatenate((x[2], x[2]))\n",
    "\n",
    "        L = np.zeros([2 * batch_size])\n",
    "        L[0:batch_size] = 1\n",
    "\n",
    "        inputs = [x_tgt_img_disc, x_src_pose_disc, x_tgt_pose_disc]\n",
    "        d_loss = discriminator.train_on_batch(inputs, L)\n",
    "\n",
    "        # Train the discriminator a couple of iterations before starting the gan\n",
    "        if step < 5:\n",
    "            util.printProgress(step, 0, [0, d_loss])\n",
    "            step += 1\n",
    "            continue\n",
    "\n",
    "        # TRAIN GAN\n",
    "        L = np.ones([batch_size])\n",
    "        x, y = next(train_feed)\n",
    "        g_loss = gan.train_on_batch(x, [y, L])\n",
    "        util.printProgress(step, 0, [g_loss[1], d_loss])\n",
    "\n",
    "        if step % params['model_save_interval'] == 0 and step > 0:\n",
    "            generator.save(network_dir + '/' + str(step) + '.h5')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 3:\n",
    "        print(\"Need model name and gpu id as command line arguments.\")\n",
    "    else:\n",
    "        train(sys.argv[1], sys.argv[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = param.get_general_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IMG_HEIGHT': 256,\n",
       " 'IMG_WIDTH': 256,\n",
       " 'batch_size': 4,\n",
       " 'data_dir': '/mnt/data/jarvislam1999/posewarp-cvpr2018/data',\n",
       " 'limbs': [[0, 1],\n",
       "  [2, 3],\n",
       "  [3, 4],\n",
       "  [5, 6],\n",
       "  [6, 7],\n",
       "  [8, 9],\n",
       "  [9, 10],\n",
       "  [11, 12],\n",
       "  [12, 13],\n",
       "  [2, 5, 8, 11]],\n",
       " 'max_px_shift': 10,\n",
       " 'max_rotate_degree': 5,\n",
       " 'max_sat_factor': 0.05,\n",
       " 'model_save_dir': '/mnt/data/jarvislam1999/posewarp-cvpr2018/models',\n",
       " 'model_save_interval': 1000,\n",
       " 'n_joints': 14,\n",
       " 'n_limbs': 10,\n",
       " 'n_training_iter': 200000,\n",
       " 'obj_scale_factor': 1.14,\n",
       " 'posemap_downsample': 2,\n",
       " 'project_dir': '/mnt/data/jarvislam1999/posewarp-cvpr2018',\n",
       " 'scale_max': 1.05,\n",
       " 'scale_min': 0.9,\n",
       " 'sigma_joint': 1.75,\n",
       " 'test_interval': 500}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'vgg_100000.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_dir = params['model_save_dir'] + '/' + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/data/jarvislam1999/posewarp-cvpr2018/models/vgg_100000.h5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/data/jarvislam1999/posewarp-cvpr2018/data'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['data_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(params['model_save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(params['model_save_dir']):\n",
    "    os.mkdir(params['model_save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feed = data_generation.create_feed(params, params['data_dir'], 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object warp_example_generator at 0x7f44e0186f10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    gan_lr = 1e-4\n",
    "    disc_lr = 1e-4\n",
    "    disc_loss = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jarvislam1999/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "generator = networks.network_posewarp(params)\n",
    "generator.load_weights('../models/vgg_100000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminator = networks.discriminator(params)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=disc_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_model = truncated_vgg.vgg_norm()\n",
    "networks.make_trainable(vgg_model, False)\n",
    "response_weights = sio.loadmat('../data/vgg_activation_distribution_train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gan = networks.gan(generator, discriminator, params)\n",
    "gan.compile(optimizer=Adam(lr=gan_lr),\n",
    "            loss=[networks.vgg_loss(vgg_model, response_weights, 12), 'binary_crossentropy'],\n",
    "            loss_weights=[1.0, disc_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jarvislam1999/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarvislam1999/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,0,0,0.693025\n",
      "1,0,0,0.691994\n",
      "2,0,0,0.691077\n",
      "3,0,0,0.689934\n",
      "4,0,0,0.687781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarvislam1999/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jarvislam1999/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "5,0,0.201712,0.686351\n",
      "6,0,0.129514,0.689191\n",
      "7,0,0.160695,0.687801\n",
      "8,0,0.244807,0.687282\n",
      "9,0,0.17936,0.69042\n"
     ]
    }
   ],
   "source": [
    "    n_iters = 10\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    for step in range(n_iters):\n",
    "\n",
    "        x, y = next(train_feed)\n",
    "\n",
    "        gen = generator.predict(x)\n",
    "\n",
    "        # Train discriminator\n",
    "        x_tgt_img_disc = np.concatenate((y, gen))\n",
    "        x_src_pose_disc = np.concatenate((x[1], x[1]))\n",
    "        x_tgt_pose_disc = np.concatenate((x[2], x[2]))\n",
    "\n",
    "        L = np.zeros([2 * batch_size])\n",
    "        L[0:batch_size] = 1\n",
    "\n",
    "        inputs = [x_tgt_img_disc, x_src_pose_disc, x_tgt_pose_disc]\n",
    "        d_loss = discriminator.train_on_batch(inputs, L)\n",
    "\n",
    "        # Train the discriminator a couple of iterations before starting the gan\n",
    "        if step < 5:\n",
    "            util.printProgress(step, 0, [0, d_loss])\n",
    "            step += 1\n",
    "            continue\n",
    "\n",
    "        # TRAIN GAN\n",
    "        L = np.ones([batch_size])\n",
    "        x, y = next(train_feed)\n",
    "        g_loss = gan.train_on_batch(x, [y, L])\n",
    "        util.printProgress(step, 0, [g_loss[1], d_loss])\n",
    "\n",
    "        if step % params['model_save_interval'] == 0 and step > 0:\n",
    "            generator.save(network_dir + '/' + str(step) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
